#!/usr/bin/env python3
import random
import math
import uuid
import logging
import sys
import os

# Add project root to path if running this file directly
if __name__ == "__main__":
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
    sys.path.insert(0, project_root)
    from src.utils.logging_config import configure_logging, get_logger
    configure_logging()
else:
    from src.utils.logging_config import get_logger

logger = get_logger(__name__)

class CoreLaws:
    """
    Defines the basic operational laws governing node behavior.
    These laws control energy dynamics, mutation, and learning rates
    for the capability nodes in the system.
    """
    def __init__(self,
                 learning_rate: float = 0.01,
                 energy_decay: float = 0.1,
                 base_energy_gain: float = 1.0,
                 mutation_rate: float = 0.005,
                 energy_scaling: float = 1.0,
                 adaptation_rate: float = 0.02,
                 cooperation_bonus: float = 0.15,
                 specialization_reward: float = 0.1,
                 law_id: str = None):
        """
        Initialize CoreLaws with operational parameters.
        
        Args:
            learning_rate: Rate at which nodes improve with successful tasks
            energy_decay: Natural energy decay rate
            base_energy_gain: Base amount of energy gained from successful operations
            mutation_rate: Probability of mutation during reproduction
            energy_scaling: Scaling factor for energy operations
            adaptation_rate: Rate at which nodes adapt to recurring tasks
            cooperation_bonus: Bonus for successful cooperative operations
            specialization_reward: Reward for specializing in particular capabilities
            law_id: Unique identifier for this law instance
        """
        self.learning_rate = learning_rate
        self.energy_decay = energy_decay
        self.base_energy_gain = base_energy_gain
        self.mutation_rate = mutation_rate
        self.energy_scaling = energy_scaling
        self.adaptation_rate = adaptation_rate
        self.cooperation_bonus = cooperation_bonus
        self.specialization_reward = specialization_reward
        self.law_id = law_id or str(uuid.uuid4())
        
        # Track operational statistics
        self.stats = {
            "energy_granted": 0.0,
            "energy_decayed": 0.0,
            "mutations": 0,
            "adaptation_events": 0,
            "cooperation_events": 0
        }
        
        logger.debug(f"CoreLaws initialized with ID: {self.law_id}")

    def apply_energy_dynamics(self, current_energy: float, task_success: bool = True, task_complexity: float = 1.0) -> float:
        """
        Applies basic energy gain/decay with success-based adjustments.
        
        Args:
            current_energy: Current energy level
            task_success: Whether the task was successful
            task_complexity: Complexity factor of the task (higher = more energy)
            
        Returns:
            float: Updated energy level
        """
        # Base decay applies to all nodes
        decay = self.energy_decay * self.energy_scaling
        
        # Calculate energy gain based on success and complexity
        if task_success:
            # Successful tasks earn energy proportional to complexity
            gain = self.base_energy_gain * task_complexity * self.energy_scaling
            
            # Add randomness for variability (optional)
            gain *= random.uniform(0.8, 1.2)
        else:
            # Failed tasks get minimal energy
            gain = self.base_energy_gain * 0.1 * self.energy_scaling
        
        # Update stats
        self.stats["energy_granted"] += gain
        self.stats["energy_decayed"] += decay
        
        # Calculate new energy level, prevent negative energy
        new_energy = max(0.0, current_energy + gain - decay)
        
        return new_energy

    def calculate_learning_adjustment(self, capability_level: float, task_success: bool,
                                     consecutive_successes: int = 0) -> float:
        """
        Calculates learning adjustment based on task results and history.
        
        Args:
            capability_level: Current capability level (0.0 to 1.0)
            task_success: Whether the task was successful
            consecutive_successes: Number of consecutive successful tasks
            
        Returns:
            float: Adjustment to capability level
        """
        # Base adjustment depends on success/failure
        if task_success:
            # Successful tasks improve capability
            # Learning gets harder as capability increases (diminishing returns)
            adjustment = self.learning_rate * (1.0 - capability_level**2)
            
            # Bonus for consecutive successes (momentum)
            if consecutive_successes > 1:
                adjustment += self.learning_rate * 0.2 * min(consecutive_successes, 5)
        else:
            # Failed tasks slightly decrease capability
            adjustment = -self.learning_rate * 0.5
        
        # Ensure capability stays in valid range after adjustment
        projected_capability = capability_level + adjustment
        if projected_capability > 1.0:
            adjustment = 1.0 - capability_level
        elif projected_capability < 0.0:
            adjustment = -capability_level
            
        return adjustment

    def should_mutate(self) -> bool:
        """
        Determines if a mutation should occur based on mutation rate.
        
        Returns:
            bool: True if mutation should occur
        """
        return random.random() < self.mutation_rate

    def apply_adaptation(self, capability_history: list) -> float:
        """
        Calculates adaptation bonus based on task history.
        
        Args:
            capability_history: List of recent capability usages
            
        Returns:
            float: Adaptation bonus
        """
        if not capability_history:
            return 0.0
            
        # Count repeated tasks
        task_counts = {}
        for task in capability_history:
            task_counts[task] = task_counts.get(task, 0) + 1
            
        # Find most frequent task
        most_frequent = max(task_counts.items(), key=lambda x: x[1])
        
        # Calculate adaptation bonus based on specialization
        if most_frequent[1] >= 3:  # At least 3 repetitions
            self.stats["adaptation_events"] += 1
            return self.adaptation_rate * most_frequent[1] * self.specialization_reward
            
        return 0.0

    def calculate_cooperation_bonus(self, collaborating_nodes: int) -> float:
        """
        Calculates bonus for nodes working together.
        
        Args:
            collaborating_nodes: Number of nodes collaborating
            
        Returns:
            float: Cooperation energy bonus
        """
        if collaborating_nodes <= 1:
            return 0.0
            
        # Bonus increases with more collaborators but has diminishing returns
        bonus = self.cooperation_bonus * math.log(collaborating_nodes + 1, 2)
        self.stats["cooperation_events"] += 1
        
        return bonus

    def mutate(self):
        """
        Creates a potentially mutated version of the laws for offspring.
        
        Returns:
            CoreLaws: A new, potentially mutated instance
        """
        # Only mutate if the condition is met
        if not self.should_mutate():
            return CoreLaws(
                learning_rate=self.learning_rate,
                energy_decay=self.energy_decay,
                base_energy_gain=self.base_energy_gain,
                mutation_rate=self.mutation_rate,
                energy_scaling=self.energy_scaling,
                adaptation_rate=self.adaptation_rate,
                cooperation_bonus=self.cooperation_bonus,
                specialization_reward=self.specialization_reward
            )
            
        # Track mutation event
        self.stats["mutations"] += 1
        
        # Determine which parameters to mutate (randomly select 1-3)
        params_to_mutate = random.sample([
            "learning_rate", "energy_decay", "base_energy_gain", 
            "mutation_rate", "energy_scaling", "adaptation_rate",
            "cooperation_bonus", "specialization_reward"
        ], k=random.randint(1, 3))
        
        # Create new parameters dictionary starting with current values
        new_params = {
            "learning_rate": self.learning_rate,
            "energy_decay": self.energy_decay,
            "base_energy_gain": self.base_energy_gain,
            "mutation_rate": self.mutation_rate,
            "energy_scaling": self.energy_scaling,
            "adaptation_rate": self.adaptation_rate,
            "cooperation_bonus": self.cooperation_bonus,
            "specialization_reward": self.specialization_reward
        }
        
        # Apply mutations to selected parameters
        for param in params_to_mutate:
            # Different mutation strategies for different parameters
            if param == "learning_rate":
                # Learning rate between 0.001 and 0.1
                new_params[param] = max(0.001, min(0.1, new_params[param] * random.uniform(0.5, 2.0)))
            elif param == "energy_decay":
                # Energy decay between 0.01 and 0.5
                new_params[param] = max(0.01, min(0.5, new_params